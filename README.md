# ğŸ•·ï¸ Sistema de Web Scraping Avanzado

Un sistema robusto y escalable para extracciÃ³n automatizada de datos de LinkedIn Jobs y MercadoLibre Argentina, con anÃ¡lisis inteligente y exportaciÃ³n de reportes.

## ğŸ“‹ Tabla de Contenidos

- [CaracterÃ­sticas Principales](#-caracterÃ­sticas-principales)
- [Arquitectura del Sistema](#-arquitectura-del-sistema)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [ConfiguraciÃ³n](#-configuraciÃ³n)
- [Uso RÃ¡pido](#-uso-rÃ¡pido)
- [DocumentaciÃ³n Detallada](#-documentaciÃ³n-detallada)

## âœ¨ CaracterÃ­sticas Principales

### ğŸš€ **Scraping Avanzado**
- **Anti-detecciÃ³n**: TÃ©cnicas stealth para evitar bloqueos
- **Scraping asÃ­ncrono**: Procesamiento paralelo de alta velocidad
- **Reintentos inteligentes**: RecuperaciÃ³n automÃ¡tica de errores
- **GestiÃ³n de sesiones**: Login automÃ¡tico y persistencia de cookies

### ğŸ¯ **Sitios Soportados**
- **LinkedIn Jobs Argentina**: Ofertas laborales, empresas, requisitos
- **MercadoLibre Argentina**: Productos, precios, vendedores, disponibilidad

### ğŸ“Š **AnÃ¡lisis Inteligente**
- **Procesamiento de datos**: Limpieza y normalizaciÃ³n automÃ¡tica
- **Reportes CSV**: AnÃ¡lisis estadÃ­sticos listos para Excel/BI
- **MÃ©tricas de rendimiento**: Monitoreo completo del proceso
- **VisualizaciÃ³n de datos**: Reportes categorizados y rankeados

### ğŸ›¡ï¸ **Robustez y Confiabilidad**
- **Logging avanzado**: Trazabilidad completa con contexto
- **Manejo de errores**: RecuperaciÃ³n automÃ¡tica y alertas
- **ConfiguraciÃ³n flexible**: Adaptable a diferentes necesidades
- **Pool de navegadores**: OptimizaciÃ³n de recursos

## ğŸ—ï¸ Arquitectura del Sistema

```
web-scraping-system/
â”œâ”€â”€ ğŸ“ core/                    # NÃºcleo del sistema
â”‚   â”œâ”€â”€ browser.py             # GestiÃ³n de navegadores Playwright
â”‚   â”œâ”€â”€ config.py              # Configuraciones centralizadas
â”‚   â”œâ”€â”€ logger.py              # Sistema de logging avanzado
â”‚   â””â”€â”€ utils.py               # Utilidades y decoradores
â”œâ”€â”€ ğŸ“ scrapers/               # MÃ³dulos de extracciÃ³n
â”‚   â”œâ”€â”€ linkedin/              # Scraper de LinkedIn Jobs
â”‚   â””â”€â”€ mercadolibre/          # Scraper de MercadoLibre
â”œâ”€â”€ ğŸ“ processor/              # AnÃ¡lisis y procesamiento
â”‚   â””â”€â”€ data_processor.py      # Limpieza y anÃ¡lisis de datos
â”œâ”€â”€ ğŸ“ data/                   # Datos extraÃ­dos (CSV)
â”œâ”€â”€ ğŸ“ logs/                   # Archivos de log
```

## ğŸš€ InstalaciÃ³n

### InstalaciÃ³n AutomÃ¡tica

```bash
# 1. Clonar repositorio
git clone https://github.com/josequispe9/ScraperMELI-Linkedin.git
cd ScraperMELI-Linkedin

# 2. Levantar los servicios con Docker Compose
docker-compose up --build


## âš™ï¸ ConfiguraciÃ³n

### Variables de Entorno

Crear archivo `.env` en la raÃ­z del proyecto:

```env
# LinkedIn
LINKEDIN_EMAIL=tu_email@example.com
LINKEDIN_PASSWORD=tu_password_seguro

```

### ConfiguraciÃ³n BÃ¡sica

```python
# core/config.py - Personalizar segÃºn necesidades
BROWSER_CONFIG = BrowserConfig(
    headless=True,           # Modo sin ventana grÃ¡fica
    timeout=30000,           # 30 segundos timeout
    slow_mo=100             # Delay entre acciones (ms)
)

SCRAPING_CONFIG = ScrapingConfig(
    max_retries=3,          # Reintentos por error
    delay_range=(2, 5),     # Delay aleatorio entre pÃ¡ginas
    concurrent_pages=3,     # PÃ¡ginas simultÃ¡neas
    batch_size=50          # Elementos por lote
)
```

## ğŸ¯ Uso RÃ¡pido

### Scraping de LinkedIn Jobs

```bash
# TÃ©rminos por defecto
python -m scrapers.linkedin.main

# TÃ©rminos especÃ­ficos
python -m scrapers.linkedin.main --terms "python developer" "data scientist"

# Limitar resultados
python -m scrapers.linkedin.main --max-jobs 10

# Modo de prueba (rÃ¡pido)
python -m scrapers.linkedin.main --test
```

### Scraping de MercadoLibre

```bash
# Productos por defecto
python -m scrapers.mercadolibre.main

# TÃ©rminos especÃ­ficos
python -m scrapers.mercadolibre.main --terms "notebook" "smartphone"

# Limitar productos
python -m scrapers.mercadolibre.main --max-products 30

# Modo de prueba
python -m scrapers.mercadolibre.main --test
```

### AnÃ¡lisis de Datos

```bash
# Analizar datos extraÃ­dos
python processor/data_processor.py
```


## ğŸ“š DocumentaciÃ³n Detallada

### DocumentaciÃ³n por MÃ³dulo

| MÃ³dulo | DocumentaciÃ³n | DescripciÃ³n |
|--------|---------------|-------------|
| **Core** | [ğŸ“– doc_core.md](core/doc_core.md) | Sistema base, configuraciÃ³n, logging y navegadores |
| **LinkedIn** | [ğŸ“– doc_linkedin.md](scrapers/linkedin/doc_linkedin.md) | Scraper de empleos, API reference y troubleshooting |
| **MercadoLibre** | [ğŸ“– doc_mercadolibre.md](scrapers/mercadolibre/doc_mercadolibre.md) | Scraper de productos y anÃ¡lisis de precios |
| **Processor** | [ğŸ“– doc_processor.md](processor/doc_processor.md) | Procesamiento de datos y generaciÃ³n de reportes |


## ğŸ“ˆ Resultados y Reportes

### Reportes de LinkedIn
- **empleos_por_fecha_publicacion.csv**: Empleos por antigÃ¼edad
- **empleos_por_nivel_experiencia.csv**: DistribuciÃ³n por seniority
- **empleos_por_modalidad.csv**: Remoto vs Presencial vs HÃ­brido

### Reportes de MercadoLibre
- **productos_por_rango_precio.csv**: AnÃ¡lisis de precios por categorÃ­a
- **productos_por_vendedor.csv**: EstadÃ­sticas de vendedores
- **productos_por_factor_personalizado.csv**: Ranking de valor

### Reporte Resumen
- **reporte_resumen.csv**: EstadÃ­sticas generales consolidadas
