import asyncio
from playwright.async_api import async_playwright
import csv
from datetime import datetime
import random
import re
import time
from core.config import BROWSER_CONFIG, SCRAPING_CONFIG, LINKEDIN_CONFIG

class LinkedInJobsScraperTest:
    def __init__(self):
        self.jobs_data = []
        self.fecha_extraccion = datetime.now().strftime("%Y-%m-%d")
        
    async def wait_random(self, min_seconds=None, max_seconds=None):
        """Espera aleatoria usando configuraci√≥n"""
        if min_seconds is None or max_seconds is None:
            min_seconds, max_seconds = SCRAPING_CONFIG.delay_range
        
        # Para pruebas, usar esperas m√°s largas
        min_seconds = max(min_seconds, 3)
        max_seconds = max(max_seconds, 8)
        
        wait_time = random.uniform(min_seconds, max_seconds)
        print(f"‚è≥ Esperando {wait_time:.1f} segundos...")
        await asyncio.sleep(wait_time)
    
    async def setup_browser(self, playwright):
        """Configuraci√≥n del navegador usando config module"""
        print("üîß Configurando navegador...")
        browser = await playwright.chromium.launch(
            headless=BROWSER_CONFIG.headless,
            slow_mo=BROWSER_CONFIG.slow_mo,
            args=[
                '--no-sandbox',
                '--disable-blink-features=AutomationControlled',
                '--disable-dev-shm-usage',
                '--disable-extensions',
                '--no-first-run',
                '--disable-default-apps',
                '--disable-automation',
                '--disable-web-security',
                '--allow-running-insecure-content',
                '--disable-features=VizDisplayCompositor'  # A√±adido para mejor compatibilidad
            ]
        )
        
        # Contexto con configuraci√≥n del m√≥dulo
        context = await browser.new_context(
            user_agent=BROWSER_CONFIG.get_random_user_agent(),
            viewport={
                'width': BROWSER_CONFIG.viewport_width, 
                'height': BROWSER_CONFIG.viewport_height
            },
            locale='es-AR',
            timezone_id='America/Argentina/Buenos_Aires',
            permissions=[],
            extra_http_headers={
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
                'Accept-Language': 'es-AR,es;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'DNT': '1',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'none',
                'Sec-Fetch-User': '?1',
                'Cache-Control': 'max-age=0'
            }
        )
        
        page = await context.new_page()
        page.set_default_timeout(BROWSER_CONFIG.timeout)
        
        # Scripts para ocultar automation
        await page.add_init_script("""
            // Ocultar webdriver
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined,
            });
            
            // Ocultar chrome automation
            window.chrome = {
                runtime: {},
            };
            
            // Ocultar plugins automation
            Object.defineProperty(navigator, 'plugins', {
                get: () => [1, 2, 3, 4, 5],
            });
            
            // Ocultar languages automation
            Object.defineProperty(navigator, 'languages', {
                get: () => ['es-AR', 'es', 'en'],
            });
        """)
        
        return browser, page
    
    async def check_linkedin_access(self, page):
        """Verificar que podemos acceder a LinkedIn sin problemas"""
        try:
            print("üåê Verificando acceso a LinkedIn...")
            await page.goto("https://www.linkedin.com", wait_until="domcontentloaded", timeout=30000)
            await self.wait_random(5, 8)
            
            # Verificar si estamos bloqueados
            title = await page.title()
            print(f"üìÑ T√≠tulo de p√°gina: {title}")
            
            if "blocked" in title.lower() or "security" in title.lower():
                print("üö´ ADVERTENCIA: Posible bloqueo detectado")
                return False
                
            # Verificar si hay CAPTCHA
            captcha = await page.query_selector('iframe[title*="captcha"], div[class*="captcha"]')
            if captcha:
                print("üîí CAPTCHA detectado - necesitar√°s resolverlo manualmente")
                input("Resuelve el CAPTCHA y presiona Enter para continuar...")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Error accediendo a LinkedIn: {e}")
            return False
    
    async def handle_auth_check(self, page):
        """Manejo de autenticaci√≥n usando credenciales del config"""
        try:
            await self.wait_random(3, 5)
            
            # Verificar m√∫ltiples formas de login
            login_selectors = [
                'form[data-id="sign-in-form"]',
                '.sign-in-form',
                'a[href*="login"]',
                'button[data-tracking-control-name="guest_homepage-basic_nav-header-signin"]'
            ]
            
            for selector in login_selectors:
                login_element = await page.query_selector(selector)
                if login_element:
                    print("üîê LinkedIn requiere autenticaci√≥n")
                    
                    # Verificar si tenemos credenciales en el config
                    if LINKEDIN_CONFIG.email and LINKEDIN_CONFIG.password:
                        print("üîë Usando credenciales del archivo de configuraci√≥n")
                        success = await self.auto_login(page)
                        if success:
                            print("‚úÖ Login autom√°tico exitoso")
                            return True
                        else:
                            print("‚ùå Login autom√°tico fall√≥, requiere intervenci√≥n manual")
                    
                    print("‚ö†Ô∏è  Procediendo con login manual...")
                    print("‚ö†Ô∏è  IMPORTANTE: Inicia sesi√≥n MANUALMENTE en la ventana del navegador")
                    print("‚ö†Ô∏è  NO uses credenciales automatizadas")
                    print("‚ö†Ô∏è  Aseg√∫rate de completar cualquier verificaci√≥n de seguridad")
                    input("\n‚úã Presiona Enter SOLO despu√©s de iniciar sesi√≥n completamente...")
                    await self.wait_random(5, 8)
                    return True
            
            return False
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Error en verificaci√≥n de autenticaci√≥n: {e}")
            return False
    
    async def auto_login(self, page):
        """Intento de login autom√°tico (USAR CON PRECAUCI√ìN)"""
        try:
            print("üîÑ Navegando a p√°gina de login...")
            await page.goto("https://www.linkedin.com/login", wait_until="domcontentloaded")
            await self.wait_random(2, 4)
            
            # Buscar campos de email y password
            email_field = await page.query_selector('#username')
            password_field = await page.query_selector('#password')
            login_button = await page.query_selector('button[type="submit"]')
            
            if not all([email_field, password_field, login_button]):
                print("‚ùå No se encontraron los campos de login")
                return False
            
            # Rellenar formulario con delay humano
            print("‚úçÔ∏è  Rellenando email...")
            await email_field.type(LINKEDIN_CONFIG.email, delay=random.randint(50, 150))
            await self.wait_random(1, 2)
            
            print("‚úçÔ∏è  Rellenando password...")
            await password_field.type(LINKEDIN_CONFIG.password, delay=random.randint(50, 150))
            await self.wait_random(1, 2)
            
            print("üîò Haciendo click en login...")
            await login_button.click()
            await self.wait_random(5, 8)
            
            # Verificar si el login fue exitoso - CORREGIDO
            current_url = page.url
            print(f"üîç URL actual despu√©s del login: {current_url}")
            
            # Verificar m√∫ltiples indicadores de login exitoso
            login_success_indicators = [
                "feed" in current_url.lower(),
                "jobs" in current_url.lower(), 
                "mynetwork" in current_url.lower(),
                current_url == "https://www.linkedin.com/"
            ]
            
            # Tambi√©n verificar elementos de la p√°gina
            feed_element = await page.query_selector('[data-test-id="main-feed"], .feed-container, .scaffold-layout')
            profile_element = await page.query_selector('button[data-test-id="nav-user-btn"], .global-nav__me')
            
            if any(login_success_indicators) or feed_element or profile_element:
                print("‚úÖ Login autom√°tico exitoso")
                
                # Guardar estado de la sesi√≥n si est√° configurado
                if SCRAPING_CONFIG.storage_state_path:
                    try:
                        await page.context.storage_state(path=SCRAPING_CONFIG.storage_state_path)
                        print(f"üíæ Estado de sesi√≥n guardado en {SCRAPING_CONFIG.storage_state_path}")
                    except Exception as e:
                        print(f"‚ö†Ô∏è  No se pudo guardar el estado de sesi√≥n: {e}")
                
                return True
            else:
                print("‚ùå Login autom√°tico fall√≥ - posible verificaci√≥n requerida")
                return False
                
        except Exception as e:
            print(f"‚ùå Error en login autom√°tico: {e}")
            return False
    
    async def safe_job_search(self, page, search_term, max_jobs=5):
        """B√∫squeda MUY conservadora de empleos usando configuraci√≥n - CORREGIDA"""
        try:
            # Primero navegar directamente a la secci√≥n de jobs
            print("üîç Navegando a la secci√≥n de empleos...")
            await page.goto("https://www.linkedin.com/jobs/", wait_until="domcontentloaded")
            await self.wait_random(3, 5)
            
            # Verificar que estamos en la p√°gina de jobs
            current_url = page.url
            print(f"üîç URL actual: {current_url}")
            
            # Buscar caja de b√∫squeda de empleos
            search_box_selectors = [
                'input[aria-label*="Buscar empleos"]',
                'input[placeholder*="Buscar empleos"]',
                '.jobs-search-box__text-input',
                'input[data-test-id="job-search-bar-keywords"]',
                '#jobs-search-box-keyword-id-ember'
            ]
            
            search_box = None
            for selector in search_box_selectors:
                try:
                    search_box = await page.query_selector(selector)
                    if search_box:
                        print(f"‚úÖ Encontrada caja de b√∫squeda con selector: {selector}")
                        break
                except:
                    continue
            
            if not search_box:
                print("‚ùå No se encontr√≥ la caja de b√∫squeda de empleos")
                # Intentar con URL de b√∫squeda directa
                print("üîÑ Intentando con URL de b√∫squeda directa...")
                search_url = f"https://www.linkedin.com/jobs/search/?keywords={search_term.replace(' ', '%20')}&location=Argentina"
                await page.goto(search_url, wait_until="domcontentloaded")
                await self.wait_random(5, 8)
            else:
                # Realizar b√∫squeda usando la caja de b√∫squeda
                print(f"üîç Buscando: {search_term}")
                await search_box.clear()
                await search_box.type(search_term, delay=random.randint(50, 150))
                await self.wait_random(2, 3)
                
                # Buscar bot√≥n de b√∫squeda
                search_button_selectors = [
                    'button[aria-label*="Buscar empleos"]',
                    '.jobs-search-box__submit-button',
                    'button[data-test-id="job-search-bar-submit"]'
                ]
                
                for selector in search_button_selectors:
                    try:
                        search_button = await page.query_selector(selector)
                        if search_button:
                            await search_button.click()
                            break
                    except:
                        continue
                else:
                    # Si no encuentra bot√≥n, usar Enter
                    await search_box.press('Enter')
                
                await self.wait_random(5, 8)
            
            # Verificar que la p√°gina de resultados carg√≥
            title = await page.title()
            print(f"üìÑ T√≠tulo de p√°gina despu√©s de b√∫squeda: {title}")
            
            # Buscar elementos de empleo con selectores m√°s amplios
            job_selectors = [
                '.job-search-card',
                '.jobs-search-results__list-item',
                '.base-search-card',
                '[data-entity-urn*="job"]',
                '.jobs-search__results-list li',
                '.job-card-container',
                '.scaffold-layout__list-container li'
            ]
            
            jobs_found = []
            print("üîç Buscando elementos de empleo...")
            
            for selector in job_selectors:
                try:
                    elements = await page.query_selector_all(selector)
                    if elements:
                        print(f"‚úÖ Encontrados {len(elements)} elementos con selector: {selector}")
                        jobs_found.extend(elements[:max_jobs])
                        break
                except Exception as e:
                    print(f"‚ö†Ô∏è  Error con selector {selector}: {e}")
                    continue
            
            if not jobs_found:
                print("‚ö†Ô∏è  No se encontraron elementos de empleo")
                print("üîç Intentando selectores adicionales...")
                
                # Selectores m√°s generales como √∫ltimo recurso
                generic_selectors = [
                    'li[data-occludable-job-id]',
                    'div[data-job-id]',
                    'article',
                    '.artdeco-list__item'
                ]
                
                for selector in generic_selectors:
                    try:
                        elements = await page.query_selector_all(selector)
                        if elements:
                            print(f"‚úÖ Encontrados {len(elements)} elementos gen√©ricos con: {selector}")
                            jobs_found.extend(elements[:max_jobs])
                            break
                    except:
                        continue
            
            if not jobs_found:
                print("‚ùå No se pudieron encontrar empleos")
                # Debug: Guardar screenshot y HTML
                try:
                    await page.screenshot(path='debug_jobs_page.png')
                    print("üì∏ Screenshot guardada como debug_jobs_page.png")
                    
                    page_content = await page.content()
                    with open('debug_jobs_page.html', 'w', encoding='utf-8') as f:
                        f.write(page_content)
                    print("üìù HTML guardado como debug_jobs_page.html")
                except:
                    pass
                
                return False
            
            print(f"üìä Procesando {len(jobs_found)} elementos de empleo")
            
            # Extraer datos de forma muy conservadora
            for i, job_element in enumerate(jobs_found[:max_jobs]):
                print(f"\nüìã Procesando empleo {i+1}/{min(len(jobs_found), max_jobs)}")
                
                job_data = await self.extract_job_data_safe(job_element, i+1)
                if job_data:
                    self.jobs_data.append(job_data)
                    print(f"‚úÖ Extra√≠do: {job_data.get('titulo_puesto', 'N/A')}")
                else:
                    print("‚ö†Ô∏è  No se pudo extraer datos del empleo")
                
                # Espera usando configuraci√≥n (pero m√°s larga para pruebas)
                await self.wait_random(8, 15)
            
            return True
            
        except Exception as e:
            print(f"‚ùå Error en b√∫squeda de empleos: {e}")
            return False
    
    async def extract_job_data_safe(self, job_element, index):
        """Extracci√≥n de datos MUY segura y robusta - MEJORADA"""
        try:
            job_data = {
                "indice": index,
                "fecha_extraccion": self.fecha_extraccion,
                "titulo_puesto": "No encontrado",
                "empresa": "No encontrado", 
                "ubicacion": "No encontrado",
                "url_empleo": "No encontrado",
                "descripcion_breve": "No encontrado"
            }
            
            # M√∫ltiples selectores para t√≠tulo - AMPLIADOS
            title_selectors = [
                '.base-search-card__title a',
                '.job-search-card__title a',
                'h3 a',
                'h4 a',
                '[data-tracking-control-name="public_jobs_jserp-result_search-card"] h3 a',
                '.job-card-list__title a',
                '.jobs-search-results__list-item h3 a',
                'a[data-tracking-control-name*="job"]',
                '.scaffold-layout__list-detail h3 a'
            ]
            
            for selector in title_selectors:
                try:
                    title_element = await job_element.query_selector(selector)
                    if title_element:
                        title_text = await title_element.inner_text()
                        if title_text and title_text.strip():
                            job_data["titulo_puesto"] = title_text.strip()
                            
                            # Obtener URL
                            href = await title_element.get_attribute("href")
                            if href:
                                if href.startswith("http"):
                                    job_data["url_empleo"] = href
                                else:
                                    job_data["url_empleo"] = f"https://www.linkedin.com{href}"
                            break
                except:
                    continue
            
            # Si no encontramos t√≠tulo con links, buscar texto directo
            if job_data["titulo_puesto"] == "No encontrado":
                title_text_selectors = [
                    'h3',
                    'h4',
                    '.job-title',
                    '[data-test-id*="title"]'
                ]
                
                for selector in title_text_selectors:
                    try:
                        title_element = await job_element.query_selector(selector)
                        if title_element:
                            title_text = await title_element.inner_text()
                            if title_text and title_text.strip():
                                job_data["titulo_puesto"] = title_text.strip()
                                break
                    except:
                        continue
            
            # M√∫ltiples selectores para empresa - AMPLIADOS
            company_selectors = [
                '.base-search-card__subtitle a',
                '.job-search-card__subtitle-link',
                'h4 a',
                '.base-search-card__subtitle',
                '.job-card-container__company-name',
                '.jobs-search-results__list-item h4',
                '[data-test-id*="company"]'
            ]
            
            for selector in company_selectors:
                try:
                    company_element = await job_element.query_selector(selector)
                    if company_element:
                        company_text = await company_element.inner_text()
                        if company_text and company_text.strip():
                            job_data["empresa"] = company_text.strip()
                            break
                except:
                    continue
            
            # M√∫ltiples selectores para ubicaci√≥n - AMPLIADOS
            location_selectors = [
                '.job-search-card__location',
                '.base-search-card__metadata',
                '.job-search-card__subtitle + div',
                '.job-card-container__metadata',
                '[data-test-id*="location"]'
            ]
            
            for selector in location_selectors:
                try:
                    location_element = await job_element.query_selector(selector)
                    if location_element:
                        location_text = await location_element.inner_text()
                        if location_text and location_text.strip():
                            # Limpiar texto de ubicaci√≥n
                            clean_location = re.sub(r'\s+', ' ', location_text.strip())
                            job_data["ubicacion"] = clean_location
                            break
                except:
                    continue
            
            # Intentar extraer descripci√≥n breve si est√° disponible
            description_selectors = [
                '.job-search-card__snippet',
                '.base-search-card__snippet',
                '.job-card-container__snippet'
            ]
            
            for selector in description_selectors:
                try:
                    desc_element = await job_element.query_selector(selector)
                    if desc_element:
                        desc_text = await desc_element.inner_text()
                        if desc_text and desc_text.strip():
                            job_data["descripcion_breve"] = desc_text.strip()[:200]  # Limitar longitud
                            break
                except:
                    continue
            
            return job_data
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Error extrayendo empleo {index}: {e}")
            return None
    
    def save_test_results(self, filename="linkedin_test_results.csv"):
        """Guardar resultados de prueba"""
        if not self.jobs_data:
            print("‚ö†Ô∏è  No hay datos para guardar")
            return
        
        try:
            with open(filename, "w", newline="", encoding="utf-8") as f:
                if self.jobs_data:
                    fieldnames = list(self.jobs_data[0].keys())
                    writer = csv.DictWriter(f, fieldnames=fieldnames)
                    writer.writeheader()
                    writer.writerows(self.jobs_data)
            
            print(f"‚úÖ Resultados de prueba guardados en {filename}")
            print(f"üìä Total de empleos extra√≠dos: {len(self.jobs_data)}")
            
        except Exception as e:
            print(f"‚ùå Error guardando resultados: {e}")

# Funci√≥n de prueba principal
async def test_scraper():
    """Funci√≥n de prueba MUY conservadora - MEJORADA"""
    print("üß™ INICIANDO PRUEBA DE SCRAPER LINKEDIN")
    print("=" * 50)
    print("‚ö†Ô∏è  ADVERTENCIAS IMPORTANTES:")
    print("   - Esta es una prueba muy limitada (m√°ximo 5 empleos)")
    print("   - Usa esperas largas entre acciones")
    print("   - Requiere intervenci√≥n manual para login")
    print("   - Detente si detectas cualquier problema")
    print("   - LinkedIn puede bloquear tu cuenta")
    print("=" * 50)
    
    response = input("\n¬øContinuar con la prueba? (si/no): ").lower()
    if response not in ['si', 's', 'yes', 'y']:
        print("üõë Prueba cancelada por el usuario")
        return
    
    scraper = LinkedInJobsScraperTest()
    
    async with async_playwright() as p:
        browser, page = await scraper.setup_browser(p)
        
        try:
            # Paso 1: Verificar acceso b√°sico
            print("\nüîç PASO 1: Verificando acceso a LinkedIn...")
            if not await scraper.check_linkedin_access(page):
                print("‚ùå No se pudo acceder a LinkedIn")
                return
            
            # Paso 2: Manejar autenticaci√≥n
            print("\nüîê PASO 2: Verificando autenticaci√≥n...")
            await scraper.handle_auth_check(page)
            
            # Paso 3: Prueba de b√∫squeda muy conservadora
            print("\nüîç PASO 3: Realizando b√∫squeda de prueba...")
            search_term = "Python Developer"  # T√©rmino b√°sico
            success = await scraper.safe_job_search(page, search_term, max_jobs=3)  # Solo 3 empleos
            
            if success:
                print("‚úÖ Prueba completada exitosamente")
            else:
                print("‚ö†Ô∏è  Prueba completada con problemas")
            
            # Paso 4: Guardar resultados
            print("\nüíæ PASO 4: Guardando resultados...")
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"linkedin_test_{timestamp}.csv"
            scraper.save_test_results(filename)
            
        except Exception as e:
            print(f"‚ùå Error durante la prueba: {e}")
        
        finally:
            print("\nüîÑ Cerrando navegador...")
            await scraper.wait_random(3, 5)
            await browser.close()
    
    print("\n‚úÖ Prueba finalizada")
    
    if scraper.jobs_data:
        print("\nüìä RESUMEN DE RESULTADOS:")
        for i, job in enumerate(scraper.jobs_data, 1):
            print(f"   {i}. {job.get('titulo_puesto', 'N/A')} - {job.get('empresa', 'N/A')}")

if __name__ == "__main__":
    asyncio.run(test_scraper())